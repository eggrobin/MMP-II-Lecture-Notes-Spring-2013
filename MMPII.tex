%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%  Please follow ISO standards.  %%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%  A copy of ISO 80000-2:2009 can be found at      %
%  <http://goo.gl/fVoiF>. Keep other applicable    %
%  standards in   mind, e.g. ISO 8601:2004, etc.   %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% build options (usage:                            %
% pdflatex "<options>\input{MMPII.tex}")           %
% [\def\targetComputerModern{}]                    %
% [\def\targetPedantic{}]                          %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% TODO(eggrobin): consider using xparse for more   %
%                 refined semantic commands.       %
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[10pt]{article}

\usepackage{xltxtra}
\usepackage[stable]{footmisc}

\usepackage{polyglossia}
\setdefaultlanguage{english}
\setotherlanguages{greek,german,russian}

\usepackage{fontspec}
\setmainfont[
    SmallCapsFont={Linux Libertine Capitals O},
    Mapping=tex-text, 
    Numbers={OldStyle, Proportional}, 
    Ligatures={TeX, Common, Historical}, 
    Contextuals=WordFinal,
            ]{Linux Libertine O}
\setmonofont{Linux Libertine Mono O}
\newfontface\libertineInitialGlyph[]{Linux Libertine Initials O}

\setsansfont[Ligatures={TeX, Common}, Numbers={OldStyle, Proportional}]{Linux Biolinum O}


\usepackage[top=1.5cm, bottom=1.5cm, left=2.5cm, right=2.5cm]{geometry}

\usepackage[iso, english]{isodate} 

\usepackage{mdframed}
\usepackage{xcolor}

\usepackage[Mathematics]{semtex}

%%%% Shorthands.

%% Frequently-used sets.
\newcommand{\Rn}{{\R^n}}
\newcommand{\Schwartz}{{\SchwartzSpace\of{\Rn}}}
\newcommand{\TemperedDistributions}{{\contdual\SchwartzSpace\of{\Rn}}}

%% Freqently-used expressions.
\newcommand{\sqftnrm}{\frac{1}{\pa{2\Pi}^n} }
\newcommand{\ftnrm}{\frac{1}{\pa{2\Pi}^\frac{n}{2}} }

\newcommand{\opAdag}{\adj{\opA}}

%%%%%
\makeatletter
\define@key{lecture}{date}{\def\lectureDate{#1}}
\define@boolkey{lecture}{official}[false]{
\ifKV@lecture@official
\def\lectureOfficial{\\* There are official notes for the material covered in this lecture.}
\else
\def\lectureOfficial{}
\fi}
\makeatother
\newcounter{Lecture}
\newenvironment{lecture}[1][]{
\refstepcounter{Lecture}
\setkeys{lecture}{official, #1}

\begin{flushright}
\emph{Lecture \theLecture, \printdate{\lectureDate}.\lectureOfficial}
\end{flushright}

}{}
\newenvironment{supplemental}{
\begin{flushright}
\textsc{Supplemental}
\end{flushright}}{}

% For comments in align environments
\newcommand\commentbox[1]{\parbox{7.5cm}{#1}}


%%%% Title.

\title{Notes from the Methods of Mathematical Physics II lectures of 2013-02-19{\slash}05-30 by Prof.~Dr.~Eugene~Trubowitz}
\author{Robin~Leroy and David~Nadlinger}

\begin{document}
  \maketitle
  
  % The first three lectures are not covered by this document.
  \setcounter{Lecture}{3}  
  
  \begin{lecture}[date={2013-02-28}]
  \section{\emph{True Lies}: An introduction to distribution theory}
  In many areas of physics, the Dirac delta ``function'' is an important tool, e.g., for describing localized phenomena. While it is usually described in vague terms as ``only making sense under an integral'', physicists tend to still write identities such as
  \begin{equation*}
    \Laplacian\frac{1}{\norm{\vx}} = -4 \Pi \DiracDelta\of\vx\text{,}
  \end{equation*}
  and rely on their intuition and previous mistakes to distinguish situations in which they can safely apply this calculus from the ones where that would lead to incorrect results.

  How can we formalize this? Note that the operation of taking the integral of the Dirac delta multiplied with another function $\gj$ can be considered as a map from that function to a scalar in $\C$. Thus, we could consider
  \begin{equation*}
    \DiracDelta[\vx]\of\gj = \int\Rn \DiracDelta\of{\vx - \vy} \gj\of\vy \diffd\vy
  \end{equation*}
  to be a functional, and more specifically an element of the dual space of whatever class of functions we can allow for $\gj$. But the question is: what restrictions do we need on this space of functions if we want to find objects like the Dirac delta in its dual space?
  
  Actually, we want these functionals to be in the continuous dual of our space, that is, we want them to be functionals $U$ such that $\conv {U\of{\gj_k}}{U\of\gj}$ for all sequence of functions $\tuplespec{\gj_k}{k\in\N}$  that converge to $\gj$ in an appropriate norm\footnote{This simply means that $U$ is a continuous map from the function space endowed with its norm topology to $\R$ endowed with the standard topology.} --- we want our space to be a Banach space.
Intuition tells us that the smaller, i.e., more restricted, a space of functions is, the stronger the conditions on $\conv{\gj_k}{\gj}$ must be in order for it to be complete, and so the bigger its continuous dual can be, as we only need $\conv {U\of{\gj_k}}{U\of\gj}$ for the sequences $\tuplespec{\gj_k}{k\in\N}$ that converge in that space. Thus, we will investigate a space of functions $\gj\of\vx \in \Continf\of\Rn$ that vanish quickly as $\conv {\norm\vx} \infty$ (``converge with a vengeance''), hoping to find the Dirac delta in its continuous dual.
  \begin{definition} First, a few definitions used throughout this course:
%TODO(eggrobin): the big partial derivative is nonsemantic.
  \begin{equation*}
    \Continf\of\Rn \DefineAs \setst{\FunctionSpec\gj\Rn\C}
    {\forall \miga \in \N^n, \pdop\miga\gj \in \Cont\of\Rn}
    \text{ is the space of \emph{smooth functions} from }\Rn \text{ to } \C \text{, where}
  \end{equation*}
  \begin{align*}
    \N &\DefineAs \set{0, 1, 2, \dotsc}\text{,}
    &\miga &= \tuple{\ga_1, \dotsc, \ga_n} \in \N^n \text{ is a \emph{multi-index},} \\
    \total{\miga} &\DefineAs \ga_1 + \dotsb + \ga_n\text{,}\quad
    &\pd\vx\miga &\DefineAs \frac{\partial^{\total{\miga}}}{\pd{x_1}{\ga_1} \dotsm \pd{x_n}{\ga_n}}
    \text{(we use }\pdop\miga\text{ when the variable is implicit),} \\
    \text{and }\vx^\migb &\DefineAs x_1^{\gb_1} \dotsm x_n^{\gb_n}
    \text{ for }\vx \in \Rn, \migb \in \N^n\text{.}
  \end{align*}
  \end{definition}

  \begin{definition}[Schwartz space]  Now we define the \emph{Schwartz space}
  \begin{equation*}
    \Schwartz \DefineAs \setst{\gj \in \Continf\of\Rn}{\forall \miga, \migb \in \N^n, \SchwartzNorm{\miga}{\migb}{\gj} < \infty}
    \text{, where }\SchwartzNorm{\miga}{\migb}{\gj} \DefineAs \sup_{\vx\in\R^n}\abs{\vx^\miga\pd\vx\migb \gj\of\vx}\text{.}
  \end{equation*}
  \end{definition}
  
  Note that $\gj \in \Schwartz$ implies $\lim_{\conv {\norm\vx} \infty}\pa{1+\norm{\vx}^2}^k \pd\vx\miga \gj\of\vx = 0$, as
  \begin{align*}
    \pa{1+\norm{\vx}^2}^m \pd\vx\miga \gj\of\vx 
    &= \sum{j = 0}[m] \binom{m}{j} \norm{\vx}^{2j} \pd\vx\miga \gj\of\vx \\
    &= \sum{j = 0}[m] \binom{m}{j} \pa{\sum{i=1}[n]x_i^2}^j \pd\vx\miga \gj\of\vx \\
    &= \sum{j = 0}[m] \binom{m}{j} \sum{\total{\miga} = j}\pa{\prod{i = 1}[n] x_i^{2\ga_i}} \pd\vx\miga \gj\of\vx
  \end{align*}
  and $\sup_{\vx \in \Rn}\abs{\vx^{2 \miga} \gj\of\vx}<\infty$. It immediately follows:
  \begin{lemma}
    If $\gj \in \Schwartz$, then
    \begin{equation*}
      \forall k \geq 0\quad \forall \miga \in \N^n\quad \exists C_\miga \in \R \quad \abs{\pd\vx\miga\gj\of{x}} < \frac{C_\alpha}{\pa{1 + \norm{\vx}^2}^k}\text{.}
    \end{equation*}
  \end{lemma}

  \begin{definition}[Convergence in $\Schwartz$]
    The sequence $\tuplespec{\gj_k}{k \in \N} \in \Functions\N{\pa\Schwartz}$ \emph{converges to} $\gj \in \Schwartz$ if and only if 
    \begin{equation*}
    \forall \miga, \migb \in \N^n \quad \lim_{k \rightarrow \infty}\SchwartzNorm{\miga}{\migb}{\gj_k - \gj}=0\text{.}
    \end{equation*}
    We use the notation $\conv[\Schwartz]{\gj_k}\gj$.
  \end{definition}
  \begin{definition}[Tempered distributions]
    Note that $\Schwartz$ is a complex vector space. We define that $U$ is an element of its continuous dual $\TemperedDistributions$, the space of \emph{tempered distributions}, if and only if:
    \begin{enumerate}
      \item $U$ is a linear map from $\Schwartz$ to $\C$, i.e., $U\in\Dual\SchwartzSpace\of\Rn$
      \item $U$ is continuous on $\Schwartz$, i.e. if $\conv[\Schwartz]{\gj_k}\gj$ then $\lim_{\conv k \infty}U\of{\gj_k} = U\of\gj$.
    \end{enumerate}
  \end{definition}
  
  
  Let us now consider some examples. First, define the space of locally integrable functions as follows.
  \begin{definition}[Locally integrable functions]
    \begin{equation*}
      \LspaceLoc[1]\of\Rn \DefineAs \setst{\FunctionSpec f \Rn \C}{\forall \vx \in \Rn, \exists \ge > 0, \int{\OpenBall \ge \vx}\abs{f\of\vy} \diffd{\vy} < \infty}
    \end{equation*}
  \end{definition}
  
  Now let $f \in {\LspaceLoc[1]}\of\Rn$.
  If additionally $\sup_{\vx \in \Rn}\pa{1 + \norm{\vx}^2}^{-s}\abs{f\of{\vx}} < \infty$
  for some $s > 0$ (e.g. $f\of\vx \sum{\total\migb\leq s} c_\migb \vx^\migb$),
  then 
  \begin{equation*}
    U_f\of\gj \DefineAs \int\Rn f\of{\vx} \gj\of{\vx} \diffd{x}
  \end{equation*}
  is a tempered distribution.
  \begin{definition}[Dirac delta distribution]
    Another example is the \emph{Dirac delta distribution} mentioned above, with 
    \begin{equation*}
      \DiracDelta\of\gj \DefineAs \gj\of{0}\text{,}\quad \DiracDelta[\vx]\of{\gj} \DefineAs \gj\of{\vx}\text{.}
    \end{equation*}
  \end{definition}  
  
  Distributions have the nice property that we can always differentiate them.
  \begin{definition}[Derivative of a distribution]
    Let $U\in\TemperedDistributions$. Then $\pdop\miga U$ is the distribution defined
    by 
    \begin{equation*}
      \pa{\pdop\miga U}\of{\gj} \DefineAs \pa{-1}^{\total{\miga}} U\of{\pdop\miga\gj}\quad
      \text{for }\gj \in \Schwartz\text{.}
    \end{equation*}
  \end{definition}
      This is natural, as
  \begin{align*}
    U_{\pdop\miga f}\of\gj 
    = \int\Rn\pa{\pdop\miga f\of\vx} \gj\of\vx \diffd{\vx} 
    = \pa{-1}^{\total{\miga}} \int\Rn f\of\vx \partial^\miga \gj\of\vx \diffd{\vx} 
  \end{align*}
  by integrating by parts.
  Let's find the derivative of $\abs{\placeholder}$ in the distribution world:
  \begin{align*}
    \AbsDistrib\of\gj &\DefineAs \int{-\infty}[\infty] \abs{x} \gj\of{x} \diffd{x}\\
    \pa{\derivop x \AbsDistrib}\of\gj &= - \AbsDistrib  \deriv x \gj\\
    &= - \int0[\infty] x \gj\der\of{x} \diffd{x} - \int{-\infty}[0]\pa{-x}\gj\der\of{x} \\
    &= - \diff 0 \infty {x \gj\of{x}} + \int0[\infty] \gj\of{x} \diffd{x} + 
    \diff {-\infty}{0} {x \gj\of{x}} - \int{-\infty}[0] \gj\of{x} \diffd{x} \\
    &= \int{-\infty}[\infty] \Sign\of{x} \gj\of{x} \diffd{x} = U_{\Sign}\of\gj\text{,}\\
    \text{where } \Sign\of{x} &\DefineAs
	\begin{cases}
		1  & x > 0 \\
		0  & x = 0 \\
		-1 & x < 0
	\end{cases}
    \quad\text{is the sign function.}
  \end{align*}
We define $\SignDistrib\of\gj \DefineAs \int{-\infty}[\infty] \Sign\of{x} \gj\of{x} \diffd{x}$ and write $\derivop x \mathrm{Abs} = \SignDistrib$. This corresponds to $\derivop x \abs{x} = \Sign\of{x}$ in physicist-speak.

  What about $\Laplacian\frac{1}{\norm{\vx}}$? By defining the \emph{Newtonian distribution}
  \begin{align*}
    N\of\gj &\DefineAs \int{\R^3} \frac{1}{\norm{\vx}} \gj\of\vx \diffd{\vx}\text{,}
  \intertext{we get}
    \Laplacian{N}\of\gj = \sum{j = 1}[3] \pderivop[2]{x_j}N\of\gj &= \sum{j = 1}[3]  N\of{\pderiv[2]{x_j}\gj} = \dotsb = -4 \pi \gj\of{0}\text{,}
  \intertext{in other words,}
    \Laplacian N &= -4 \pi \DiracDelta\text{.}
  \end{align*}
  \end{lecture}
  \begin{lecture}[date=2013-03-05]
  \begin{definition}[Inner product on $\Schwartz$]
  Let $\gj,\gy\in\Schwartz$. We define:
  \begin{equation*}
  \LTwoInner \gy \gj \DefineAs \int\Rn \conj\gy\of\vx \gj\of\vx \diffd\vx \text{.}
  \end{equation*}
  \end{definition}
  \end{lecture}
  \begin{lecture}[date=2013-03-07]
  \section{General properties of the Fourier transform}
  \begin{lemma}[``Your life in Fourier land depends on it.'']
    \begin{align}
      \label{FTLinearity}
      \begin{split}      
      \ft{\gj + \gy} &= \ft{\gj} + \ft{\gy}\text{,}\\
      \ft{\gl \gj} &= \gl \ft{\gj} 
      \end{split}
      \\
      \label{FTUpperBound}
      \abs{\ft{\gj}\of\vk} &\leq \ftnrm\Lnorm[1]{\gj}<\infty\text{,} &&
      \Lnorm[1]{\gj} \DefineAs \int\Rn \abs{\gj\of\vx} \diffd \vx
      \\
      \label{FTScaling}
      \ft{\gj\of{\gl\placeholder}}\of\vk &= \frac{1}{\abs{\gl}^n}\ft{\gj}\of{\frac\vk\gl}\text{,} &&
      \gl\neq 0
      \\
      \label{FTTranslation}
      \ft{T_\vy\gj}\of\vx &= \E^{\I\scal\vk\vy}\ft\gj\of\vk\text{,} &&
      \pa{T_\vy\gj}\of\vx \DefineAs \gj\of{\vx+\vy}
      \\
      \label{FTDerivative}
      \begin{split}
      \ft{\pderiv{x_j}\gj}\of\vk &= \I k_j \ft\gj\of\vk \text{,} \\ 
      \ft{x_j \gj}\of\vk &= \I \pderiv{k_j}{\ft\gj} \of\vk
      \end{split}
      \\
      \label{FTUnitary}
      \int\Rn\ft\gj\of\vy \gy\of\vy \diffd\vy &= \int\Rn \gj\of\vy \ft\gy\of\vy \diffd\vy
    \end{align}
    \begin{proof}
      Proof of (\ref{FTUpperBound}):
      \begin{equation*}
       \abs{\ft\gj\of\vk} 
        = \abs{\ftnrm\int\Rn \gj\of\vx \E^{-\I \scal\vk\vx}\diffd\vx} 
        \leq \ftnrm\int\Rn \abs{\gj\of\vx 
        \E^{-\I \scal\vk\vx}}\diffd\vx  = \ftnrm
        \underbrace{\int\Rn \abs{\gj\of\vx}}_{\Lnorm[1]{\gj}}
        \underbrace{\abs{\E^{-\I\scal\vk\vx}}}_{1}\diffd\vx \\
      \end{equation*}
      Proof of existence of the integral $\Lnorm[1]\gj$:
      \begin{align*}
        \int\Rn\abs{\gj\of\vx}\diffd\vx 
        &= \int\Rn\pa{1+\norm{\vx}^2}^\frac{s}{2}\abs{\gj\of\vx}
        \frac{\diffd\vx}{\pa{1+\norm{\vx}^2}^\frac{s}{2}}  \\
        &\leq \SchwartzNorm s\nullmi\gj \int\Rn\frac{1}{\pa{1+\norm{\vx}^2}^\frac{s}{2}}\diffd\vx\\
        &= \SchwartzNorm s\nullmi\gj \int0[\infty]\frac{r^{n-1}}{\pa{1+r^2}^\frac{s}{2}}\diffd r
        < \infty &&\text{for } s\geq n+1\text{.}
      \end{align*}
      ``(\ref{FTLinearity}) I will not do!''
      Proof of (\ref{FTScaling}):
      \begin{align*}
        \ft{\gj\of{\gl\placeholder}} 
        &= \ftnrm\int\Rn\gj\of{\gl\vx}\E^{-\I\scal\vk\vx} \diffd\vx \\
        &= \ftnrm\int\Rn\gj\of\vy\E^{-\I\scal{\frac1\gl\vk}{\vy}} \diffd\of{\frac{\vy}{\gl}}
          && \text{where } \vx=\frac1\gl\vy\text{.} \\
        &= \frac{1}{\abs\gl^n} \underbrace{
          \ftnrm\int\Rn\gj\of\vy\E^{-\I\scal{\frac\vk\gl}\vy}
          \diffd\vy}_{\ft\gj\of{\frac\vk{\gl}}}
      \end{align*}
      Proof of the second part of (\ref{FTDerivative}):
      \begin{align*}
        \ft{x_j\gj}\of\vx 
        &= \ftnrm\int\Rn x_j\gj\of{\vx}\E^{-\I\scal\vk\vx}\diffd\vx \\
        &= \ftnrm
          \int\Rn\gj\of{\vx}\I\pderivop{k_j}\E^{-\I\scal\vk\vx} \diffd\vx 
          && \text{as }\pderivop{k_j}\E^{-\I\scal\vk\vx} =
            \pderivop{k_j}\E^{-\I\sum{r=0}[n] k_j x_j}=-\I x_j \E^{-\I\scal\vk\vx}\\
        &= \I\pderivop{k_j}\ftnrm
          \int\Rn\gj\of\vx\E^{-\I\scal\vk\vx} \diffd\vx \\
        &= \I\pderiv{k_j}{\ft\gj}\of\vk
      \end{align*}
      
      \emph{The professor starts whistling some elevator music while waiting for a student to write down the proof before he can wipe the board. When the student is done, the professor notices that there still is some room left on the blackboard and starts writing the rest there, without erasing anything.}
      
      Proof of \ref{FTUnitary}:
      \begin{align*}
        \int\Rn\ft\gj\of\vy \gy\of\vy \diffd\vy
        &= \int\Rn\ftnrm\int\Rn\gj\of\vx
          \E^{-\I\scal\vy\vx}\diffd\vx\:\gy\of\vy\diffd\vy \\
        &= \int\Rn\gj\of\vx\ftnrm\int\Rn
          \E^{-\I\scal\vx\vy}\gy\of\vy\diffd\vy\diffd\vx
          && \commentbox{As $\int {\R^{2n}}\abs{\gj\of\vx
          \E^{-\I\scal\vy\vx}\gy\of\vy}\diffd\vx\diffd\vy<\infty$,
          we can use Fubini's theorem.} \\
        &=\int\Rn\gj\of\vy \ft\gy\of\vy \diffd\vy
      \end{align*}
      
      
    \end{proof}
  \end{lemma}
  
  \begin{proposition}
The Fourier transform $\ft{\placeholder}$ is a continuous bijective linear map from the Schwartz space $\Schwartz$ to itself. $\rft{\ft{\gj}}=\gj$, where $\rft\gy\of\vx\DefineAs\ftnrm \int\Rn\gy\of\vk\E^{\I\scal\vk\vx}\diffd\vx$, read ``unhat'', ``bird'', ``seagull'', or whatever you like.
  
    \begin{proof}
      \begin{align*}
        \gj\in\Schwartz&\Rightarrow\vx^\miga\pd\vx\migb\in\Schwartz \\
        \ft{\pa{\vx^\miga\pd\vx\migb\gj}}\of\vk
        &=\I^{\total\miga}\pd\vk\miga\ft{\pa{\pd\vx\migb\gj}}\of\vk 
          && \text{from the second equality in (\ref{FTDerivative}), applied }\total\miga\text{ times.} \\
        &=\I^{\total\miga}\pd\vk\miga\of{\I^{\total\migb}\vk^\migb\ft\gj}\of\vk \\
        &=\I^{\total\miga+\total\migb}\pd\vk\miga\of{\vk^\migb\ft\gj}\of\vk
      \end{align*}
      ``I should have done it the other way around. [...] Let's try it the other way around.''
      We want:
      \begin{equation*}
        \forall\miga,\migb,\sup_{\vk\in\Rn}\abs{\vk^\miga\pd\vk\migb\ft\gj\of\vk}<\infty
      \end{equation*}
      As that implies $\ft\gj\in\Schwartz$.
      \begin{align*}
        \ft{\pa{\pd\vx\miga\of{\vk^\migb\gj}}}\of\vk
        &=\I^{\total\miga+\total\migb}\vk^\miga\pd\vk\migb\ft\gj\of\vk
        && \commentbox{by applying the first part of (\ref{FTDerivative}) $\total\miga
        $ times and the second part $\total\migb$ times.}\\
        \forall\miga,\migb,\abs{\vk^\miga\pd\vk\migb\ft\gj\of\vk}
        &\leq\ftnrm\Lnorm[1]{\pd\vx\migb\of{\vx^\migb\gj}}<\infty
        && \text{from (\ref{FTUpperBound}).}
      \end{align*}
      We now know $\ft\gj\in\Schwartz$.
      Let us prove $\rft{\ft\gj}=\gj$. ``When you do the wrong thing I'm gonna scream loudly.''
      \begin{align*}
        \rft{\ft\gj}\of\vx&=\ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}\diffd\vk \\
        &=\sqftnrm\int\Rn\int\Rn\gj\of\vy\E^{-\I\scal\vk\vy}\diffd\vy\:\E^{\I\scal\vk\vx}\diffd\vk
      \end{align*}
      We don't interchange the integrals here because that would lead to ugly calculations. ``If pou paint the walls before you start building, it's not a good idea.''
      At this point, somebody suggests replacing $\sqftnrm\int\Rn \E^{\I\scal\vk{\pascal{\vx-\vy}}}\diffd\vk$ by $\DiracDelta\of{\vx-\vy}$. ``It's plausible! --- WHY? [...] Ah I said it, so it's plausible.'' However, we would need to do some nasty calculations in order to do this. ``How are we going to do it so fast that you don't get bored, and yet in enough detail that he's convinced? Be sneaky.''
      \begin{align*}
        \rft{\ft{\gj}}
        &=\ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}
        \underbrace{\lim_{\ge\downarrow 0}\E^{-\ge\frac{\norm\vk^2}{2}}}_{\mathclap{\substack{1
        \text{ written in}\\\text{some other way}}}}\diffd\vk\\
        &=\lim_{\ge\downarrow 0}\ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}
        \E^{-\ge\frac{\norm\vk^2}{2}}&&\commentbox{``Don't worry.'' This is actually a one-liner 
        using Lebesgue's dominated convergence theorem.}
      \end{align*}
      \emph{The 10-minute break ends with the loud noise of a metallic pointing stick hitting the desk.}
      \begin{align*}
        \ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}\E^{-\ge\frac{\norm\vk^2}{2}}\diffd\vk
        &=\ftnrm\int\Rn\ftnrm\int\Rn\gj\of\vy\E^{-\I\scal\vy\vk}\diffd\vy\:
        \E^{\I\scal\vk\vx}\E^{-\ge\frac{\norm\vk^2}{2}}\diffd\vk\\
        &=\ftnrm\int\Rn\gj\of\vy\ftnrm\int\Rn\E^{\I\scal\vk{\pascal{\vx-\vy}}}
        \E^{-\ge\frac{\norm\vk^2}{2}}\diffd\vk\diffd\vy
      \end{align*}
      Recall: ``every path leads to Rome and every Gaussian is in $\Schwartz$.'' Also, the last foot of a dactylic hexameter is always a spondee. 
      \begin{equation*}
        \ftnrm\int\Rn\E^{-\ge\frac{\norm\vk^2}{2}}\E^{\I\scal{\pascal{\vy-\vx}}\vk}\diffd\vk
        =\frac{\E^{-\frac{1}{2\ge}\norm{\vx-\vy}^2}}{\ge^\frac{n}{2}}
      \end{equation*}
      We therefore get:
      \begin{align*}
         \ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}\E^{-\ge\frac{\norm\vk^2}{2}}\diffd\vk
         &=\ftnrm\int\Rn\gj\of\vy\ftnrm\int\Rn\E^{\I\scal\vk{\pascal{\vx-\vy}}}
        \E^{-\ge\frac{\norm\vk^2}{2}}\diffd\vk\diffd\vy\\
        &=\ftnrm\int\Rn\gj\of\vy\frac{\E^{-\frac{1}{2\ge}\norm{\vx-\vy}^2}}
        {\ge^\frac{n}{2}}\diffd\vy \\
        &=\ftnrm\int\Rn\gj\of{\vy\sqrt\ge+\vx}\frac{\E^{-\frac{1}{2\ge}\norm{\vy\sqrt\ge}^2}}
        {\ge^\frac{n}{2}}\diffd\of{\vy\sqrt\ge} && \text{``Epsilons everywhere!''}\\    
        &=\ftnrm\int\Rn\gj\of{\vx+\vy\sqrt\ge}\E^{-\frac{1}{2}\norm\vy^2}\diffd\vy
        && \text{``Now we can paint.''}\\
        &\overset{\ge\downarrow 0}{\rightarrow}
        \ftnrm\gj\of\vx\int\Rn\E^{-\frac{1}{2}\norm\vy^2}\diffd\vy =\gj\of\vx\text{.}
      \end{align*}
    \end{proof}
  \end{proposition}
  
  \section{Seeking eigenfunctions of the Fourier transform}
  ``The main ideas of many things are right here.''
  We seek to find the solutions $\tuple{\gj,\gl}$ of
  \begin{equation*}
    \ft\gj=\gl\gj \text{.}
  \end{equation*}
  We shall find all of them. ``Not one is going to get away.'' Actually, we have already got one:
  \begin{equation*}
    \ft{\E^{-\frac{1}{2}\norm\vx^2}}=\E^{-\frac{1}{2}\norm\vx^2} \text{,}
  \end{equation*}
  so we know that 1 is an eigenvalue. How do we find the others? ``Here you actually have to have an idea.''
  
  \paragraph{Idea}
  Find an $H\in\Endomorphisms\of\Schwartz$ such that $\commutator H {\ft{\placeholder}} = 0$. Then they have the same eigenspaces, so we just need to find the eigenfunctions of $H$ (see \emph{Finite Dimensional Quantum Mechanics}).
  
  Let $n=1$.
  \begin{equation*}
    \left.
    \begin{aligned}
      \ft{\pa{x^2\gj}}\of k &= -\derivop[2]{k}\ft\gj\of k \\
      \ft{\pa{\derivop[2]{x}\gj}}\of k &= -k^2 \ft\gj\of k
    \end{aligned}
    \right\rbrace \qquad \text{From the lemma your life depends on.}
  \end{equation*}
  Subtracting the second equality from the first one above:
  \begin{equation*}
    \FT\of{\pa{-\derivop[2]{x}+x^2}\gj}\of k = \pa{-\derivop[2]{k}+k^2}\FT\gj\of k\text{,}
  \end{equation*}
  where $\FT = \ft{\placeholder}$ because things are getting a bit too big for the hat.
  We smell a harmonic potential. ``Don't get your fingers too close, they sometimes bite.''
  
  Let $\opH \DefineAs \frac{1}{2}\pa{-\derivop[2]{x}+x^2-1}$. Then $\commutator \opH {\ft{\placeholder}}=0$. We multiplied by $\frac{1}{2}$ so that it looks even more like a harmonic potential (it is the Hamiltonian of the quantum harmonic oscillator). Why did we add $-1$? Define
  \begin{align*}
    \opAdag &\DefineAs \frac{1}{\sqrt 2}\pa{\derivop{x} + x}\text{,}\\
    \opA &\DefineAs \frac{1}{\sqrt 2}\pa{-\derivop{x} + x}\text{.}
  \end{align*}
  We then have $\opH = \opAdag\opA$. If $a$ and $b$ commute, then we have $\pa{a-b}\pa{a+b}  = a^2-b^2$, but here $x$ and $\derivop{x}$ don't quite commute, hence the $-1$.
\end{lecture}
\begin{lecture}[date=2013-03-12]
Let us look at these operators in more detail: define $\pa{\opQ f}\of x \DefineAs x f\of x \in \SchwartzSpace\of{\R}$, $\pa{\opP f}\of x \DefineAs \derivop x f\of x \in \SchwartzSpace\of\R$ for $f\in\SchwartzSpace\of\R$. We saw that $\commutator \opQ \opP = 1$. We also have:
\begin{align*}
  \LTwoInner \gj {\opP\gy} 
  &= \int\R \conj\gj\of x \derivop x \gy \of x \diffd x \\
  &= \diff {-\infty}{\infty}{\conj\gj\gy} - 
    \int\R \derivop x \gj \of x \gy\of x \diffd x \\
  &= - \LTwoInner {\opP\gj} \gy \text{,}&&\parbox{7cm}{$\diff {-\infty}{\infty}{\conj\gj\gy} = 0$  as $\gj\in\SchwartzSpace\of\R$, $\gy\in\SchwartzSpace\of\R$, and therefore $\conj\gj\gy\in\SchwartzSpace\of\R$.}
\end{align*}
so $\opP$ is skew symmetric. What is better than skew symmetric? Self adjoint is better. How do we make a skew symmetric operator self adjoint? We add an $\I$. Namely, redefine $\pa{\opP f}\of x \DefineAs \frac{1}{\I}\derivop x f\of x$, we then have $\LTwoInner \gj {\opP\gy}  = \LTwoInner {\opP\gj} \gy$. $\opQ$ is obviously self adjoint. We now have $\commutator \opQ \opP = \I \Identity$. Multiplying by some $h\in\R$, redefine $\pa{\opP f}\of x \DefineAs \frac{h}{\I}\derivop x f\of x$, we get $\commutator \opQ \opP = h \I \Identity$.

If we let $h \DefineAs \ReducedPlanck$, the conditions verified by $\opP$ and $\opQ$ are the conditions for infinite matrices $\matP$ and $\matQ$ in the ``catechism of matrix mechanics'' in \emph{Finite Dimensional Quantum Mechanics}.
``Being something a little more, and something a lot less than cockroaches, we are curious.'' What we have been doing here is not the ideal way of doing this: we have to pick a vector space, in this case $\Schwartz$, last year the space of infinite matrices. As we learned in linear algebra, we gain a deeper understanding if we do not use coordinate systems. 
``We are going to study the pure essence'' of this. We are going to replace that by an abstract group, which lives in Plato's cave, and when we need to calculate, we will look at a representation. ``The group is as close to God as you can get.''

\begin{definition}[Heisenberg group]
We define the Heisenberg group, introduced by Hermann Weyl.
\begin{equation*}
\tuple{
\HeisenbergGroup \DefineAs \setst{
\begin{pmatrix}
1 & r & t\\
0 & 1 & s\\
0 & 0 & 1\\
\end{pmatrix}
}{r,s,t\in\R}, 
\text{ordinary matrix multiplication}}
\end{equation*}
\end{definition}

You know that if you take $\E^x\E^y$ on reals numbers, you get $\E^{x+y}$, but that doesn't work for matrices. Hermann Weyl's idea is the following: we look at the identities \begin{align*}
\pa{\E^{\I t P} f}\of x &= f\of{x+t}
&&\text{ as }\pa{\E^{\I t \pa{\frac{1}{\I}\derivop x}}}f\of x \overset{\text{formally}}{=} \sum{l=0}[\infty]\frac{t^l}{l!}\derivop[l] x f \of x \text{, the Taylor series of $f\of{x + t}$ at $x$.}\\
\E^{\I t P}\E^{\I s Q} &= \E^{\I s t} \E^{\I s Q} \E^{\I t P}
\end{align*}

Write $X \DefineAs \E^{\I Q}$ and $Y \DefineAs \E^{\I P}$, $X^r Y^s = \E^{\I r s} Y^s X^r$, $Z \DefineAs \pa{\E^\I}^t \Identity$. We will generate a group with these three elements. ``I'll think up another way of doing this; it's something worth doing twice.'' How do we preserve all the ideas, and yet get rid of all the infinite dimensional vector spaces? We study a finite dimensional analog, the finite Heisenberg group $\FiniteHeisenbergGroup n$, in which we use $\IntegersModulo{n}$ instead of $\R$. And we'll use that little group to do all sorts of experiments. No one will complain about what we do to it. 

Let us start again. ``Those of you who have done the exercises, and those of you who have the determination to go to Prof. Willwacher's --- `Willwacher.' I like that name. --- lecture, we are going to do that again, but on a concrete example.''
We will find all the conjugacy classes. ``We're going to hunt them down!'' 

``I'll see you on Thursday, and I expect there'll be fewer people.''
\end{lecture}
\begin{lecture}[date=2013-03-14, official=true]

\section{The finite Heisenberg group}

\emph{The professor whistles ``Singin' in the Rain'' while waiting for the lecture to start.}

In its soul, the finite Heisenberg group has captured the essence of calculating something in quantum mechanics. The point of abstraction is to remove all that gets in the way of communing with the thing in and of itself. 
``We're gonna go deep into Plato's cave today.''

``You write commutators to see the level of how much it doesn't commute (\emph{sic}).''

 ``Conjugacy is where it's at, in the language of the 1960s.'' This is what the entire linear algebra lecture is about. For instance, the Jordan normal form gives you a unique representative of a conjugacy class. ``You can dig down here and spend years in this hole. Or you can go up. I'll go up, I'll let you dig down.''

$\matX\DefineAs\Helt 1 0 0$, $\matY\DefineAs\Helt 0 1 0$, $\matZ\DefineAs\Helt 0 0 1$ generate the finite Heisenberg group. With $\matZ=\matX\matY\matX^{-1}\matY^{-1}$, $\matX$, $\matY$ generate it. ``Jacobi? --- no, no, no. No Jacobi identity.'' 

The free group on one element is isomorphic to $\tuple{\Z,+}$. The normal subgroup of $\FreeGroup X$ generated by $W$ is the smallest normal subgroup which contains $W$. This is well-defined, as $\FreeGroup X$ is such a normal subgroup, and the intersection of normal subgroups is a normal subgroup, so the normal subgroup generated by $W$ is
\begin{equation*}
  \IntersectionOver {
    \LongDomainSpec{
      \mathllap{N\NormalSubgroup} \mathrlap{\FreeGroup X}\\
      \mathllap{W\Subset} \mathrlap{N}
    }
  } N\text{.}
\end{equation*}
%\begin{supplemental}
Note that this is also equal to the orbit of $W$ under the action of $G$ on its subsets by conjugation, $\LeftConjugationAction g S \DefineAs g S g^{-1}$, so we can write
\begin{equation*}
\GroupPresentation{X}{W} = \QuotientGroup{\FreeGroup X}{\LeftConjugationAction G W} = \QuotientGroup{\FreeGroup X}{
  \IntersectionOver {
    \LongDomainSpec{
      \mathllap{N\NormalSubgroup} \mathrlap{\FreeGroup X}\\
      \mathllap{W\Subset} \mathrlap{N}
    }
  } N\text{.}
}
\end{equation*}
%\end{supplemental}

``Out of this trivial stuff comes something deep.''

``A faithful representation of a group is just changing variables.''
$\gr$ is a faithful complex irreducible representation of the finite group $G$ if and only if $\sum{g\in G} \abs{\Character[\gr]\of g}^2 = \Cardinality G$.

``I will see those of you who actually do come back next Tuesday.''
\end{lecture}
\begin{lecture}[date=2013-03-19, official=true]
The dual group only works for abelian groups. 
The way a bourgeois mathematician thinks of the classical phase space $\Rn\Cartesian\PontryaginDual\Rn$ is as the cotangent bundle $\Rn\Cartesian\Dual{\pa\Rn}$.
``If you would have the energy to learn ancient Greek, and you talked about the real housewives of Atlanta, it would be a waste.'' It is not sufficient to have a fancy language, you actually have to say something.

We started this lecture with the finite Fourier transform. This is a special case of what we discuss here, with $\IntegersModulo{n}$ as the abelian group $A$. This is perfect pedagogy: after only eight months, we come back to the beginning. Everything I've done so far is just that for various groups. When the group is infinite, e.g., the unit circle for Fourier series, you have to do analysis. ``[Claude] doesn't go there. I do.''

\end{lecture}

\begin{supplemental}
\subsection{\textgreek{Ἡ φανταχτερή γλῶσσα τῶν ἀστικῶν μαθηματικῶν}\footnote{The fancy language of bourgeois mathematicians.}}
\begingroup
\newcommand{\VelocitySpace}{\LieAlgebraSymbol{g}}
\newcommand{\MomentumSpace}{\Dual\VelocitySpace}
\newcommand{\Lagrangian}{\mathscr{L}}
\newcommand{\Hamiltonian}{\mathscr{H}}
\newcommand{\eqrel}{\sim}
Assume the space $G$ of generalised coordinates of a physical system is a Lie group, i.e., a group which is also a differentiable manifold, and in which composition and inversion are smooth maps. Then if $\FunctionSpec\vq \R G$ describes the evolution of the generalised coordinates of the system with time, the generalised velocity at time $t$, $\TimeDerivative\vq\of t$, lies in the tangent space $\TangentSpace{\vq\of t}G$ --- recall that the tangent space of $g$ at $\vx$ is defined as the set of derivatives\footnote{One has to be careful here: unless $G$ is a submanifold of $\Rn$, the derivative is not well-defined. In that case however, $\TimeDerivative \vgg\of 0$ can be defined as the equivalence class of $\vgg$ in the set of curves through $\vx$ with $\vgg\of 0 = \vx$ under the relation $\vgg_1\eqrel\vgg_2 \Equivalent \pa{f\Compose\vgg_1}\der\of 0 = \pa{f\Compose\vgg_2}\der\of 0$, where $f$ is a differentiable chart of a neighbourhood of $\vx$ onto $\Rn$. It can then be shown that this is independent of $f$. Quite often though, $G$ is naturally a submanifold of $\Rn$ and this trick is unneeded.} $\TimeDerivative \vgg\of 0$ at $0$ of smooth curves $\FunctionSpec\vgg\R G$ with $\vgg\of 0 = \vx$.

The ordered pair $\tuple{\vq\of t,\TimeDerivative\vq\of t}$ lies in the \emph{tangent bundle} $\TangentBundle G$, that is,
\begin{equation*}
\tuple{\vq\of t,\TimeDerivative\vq\of t} \in \TangentBundle G \DefineAs \UnionOver{\vx \in G} \set{\vx} \Cartesian \TangentSpace{\vx}G\text{.}
\end{equation*}
Informally, $\TangentBundle G$ is the disjoint union of all the tangent spaces of the manifold $G$. An element $\tuple{\vx,\vv}\in \TangentBundle G$  represents a tangent vector $\vv$ to $G$ at $\vx$. Physically, this is a state of the system, namely the one with coordinates $\vx$ and velocity $\vv$. 

As $G$ is a Lie group, composition on the left --- or right --- by any element is a diffeomorphism. In particular, for $q\in G$,
$\FunctionSpec {\gj_\vq} G G, \FunctionBody \vx {\vq^{-1} \vx}$ is a diffeomorphism, and so it induces a canonical linear isomorphism $\diffd \gj_\vq \of\vq$ between the tangent spaces $\TangentSpace{\vq}G$ and $\TangentSpace{\gj_\vq\vq}=\TangentSpace{\Identity}G$, by
\begin{equation*}
\diffd \gj_\vq \of\vq\TimeDerivative\vgg\of 0 = \diffd \gj_\vq \of{\vgg\of 0}\TimeDerivative\vgg\of 0 = \pa{\gj_\vq\Compose\vgg}\der\of 0 = \TimeDerivative\vgg_0\of 0\text{,}
\end{equation*}
where $\TimeDerivative\vgg\of{0}$ is an element of $\TangentSpace{\vq}G$, so $\vgg\of 0 = \vq$ and $\vgg_0 \DefineAs \gj_\vq\Compose\vgg$ verifies $\vgg_0\of 0 = \Identity$, therefore $\TimeDerivative\vgg_0\of0\in\TangentSpace\Identity G \DefinitionOf \VelocitySpace$. By definition, $\VelocitySpace$ is the Lie algebra $\LieAlgebra\of G$ associated with $G$.
It follows from this isomorphism that the tangent bundle of $G$ is \emph{parallelisable}, i.e.,
\begin{equation*}
\TangentBundle G = \UnionOver{\vx \in G} \set{\vx} \Cartesian \TangentSpace{\vx}G \Isomorphic \UnionOver{\vx \in G} \set{\vx} \Cartesian \TangentSpace\Identity G = G \Cartesian \TangentSpace\Identity G = G \Cartesian \VelocitySpace\text{,}
\end{equation*}
where the isomorphism is canonical.

Recall from Hamiltonian mechanics that for a Lagrangian
$\FunctionSpec \Lagrangian {\TangentBundle G \Cartesian \R}{\R}, \FunctionBody {\tuple{\vq,\vv,t}} {\Lagrangian\of{\vq,\vv,t}}$,
the Hamiltonian is defined as the Legendre transform of $\Lagrangian$,
\begin{equation*}
\Hamiltonian \DefineAs \sum i v_i \pderiv{v_i}\Lagrangian - \Lagrangian = \sum i v_i p_i - \Lagrangian\text{,}
\end{equation*}
where $p_i \DefineAs \pderiv{v_i}\Lagrangian$. The \emph{generalised momentum} $\FunctionNamedBody\vp \vv {\sum i v_i p_i}$ is therefore a linear form on the space $\VelocitySpace\owns\vv$. Using $\vq\of t$ as the evolution of the system as above, $\TimeDerivative\vq\of t \in \TangentSpace{\vq\of t}G$, and so $\vp\of t\in \Dual{\pa{\TangentSpace{\vq\of t}G}} \DefinitionOf \CotangentSpace{\vq\of t}G$, the \emph{cotangent space} of $G$ at $\vq$, and the tuples $\tuple{\vq,\vp}$ lie in the \emph{cotangent bundle} $\CotangentBundle G$,
\begin{equation*}
\CotangentBundle G \DefineAs \UnionOver{\vq\in G}\set\vq \Cartesian \CotangentSpace\vq G\text{.}
\end{equation*}
As the tangent spaces of $G$ are canonically isomorphic to each other, so are their duals, so we can write
\begin{equation*}
\CotangentBundle G = G \Cartesian \MomentumSpace\text{.}
\end{equation*}
The dual of the Lie algebra, $\MomentumSpace$, is the momentum space. The Hamiltonian is a function from the cotangent bundle (and time) to the reals, $\FunctionSpec\Hamiltonian {\CotangentBundle G \Cartesian \R = G \Cartesian \MomentumSpace \Cartesian \Reals} \R$.

The Pontryagin dual\footnote{The Pontryagin dual is named after %
\textrussian{Лев Семёнович Понтря́гин} (1908--1988).} $\PontryaginDual G$ is the set of homomorphisms from $G$ to $\UnitaryGroup\of 1$. Compare this with the vector space dual $\Dual V$, which is the set of linear maps from $V$ to the underlying field. One can see $\PontryaginDual G$ as a sort of non-linear analogue to $\Dual V$. We will see that for $G=\Rn$, we have a meaningful isomorphism between $\PontryaginDual G$ and $\MomentumSpace$. This will also give a motivation for defining the Hamiltonian on the \emph{cotangent} bundle and not on the tangent bundle, answering the question: \emph{why should the generalised momenta not lie in the same space as the velocities?}
\endgroup
\end{supplemental}

\begin{supplemental}
\subsection{Examples from Raisa Galimova's exercise class}
\begingroup
\newcommand{\LeftAction}[2]{f_{#1} \of{#2}}
Let $G$ be a group acting on a measure space\footnote{Here $X$ is a set, $\FunctionSpec \gm X {\intclos 0 \infty}$ is a measure on $X$ and $\gS\Subset\PowerSet X$ is the $\mathrm{\sigma}$-algebra of $\gm$-measurable subsets.} $\tuple{X, \gS, \gm}$ by the left action $\FunctionSpec f G {\Functions X X}, \FunctionBody g {f_g}$, that is, we denote by $\LeftAction g x$ the action of $g\in G$ on $x\in X$, and $f_g \Compose f_h = f_{gh}$. Define the space of square-integrable functions on $X$
\begin{align*} 
  \Lspace[2]\of X &\DefineAs \setst{\gj\in\Functions \C X}{\Lnorm[2] \gj < \infty} \text{,} \\
\intertext{where}
  \Lnorm[2] \gj &\DefineAs \LTwoInner \gj \gj \text{,} \\
  \LTwoInner \gy \gj &\DefineAs \int X \conj\gy \gj \diffd \gm\text{.} \\
\intertext{Note that if $X$ is finite, and $\gm$ is the counting measure,}
  \LTwoInner\gy\gj &= \int X \conj\gy\gj \diffd \gm = \sum {x\in X} \conj\gy\of x \gj\of x \text{,}\\
  \forall\gj\in\Functions X \C \quad  \Lnorm[2]\gj &= \int X \abs{\gj}^2 \diffd \gm = \sum {x\in X} \abs{\gj}^2  < \infty \text{,}\\
\intertext{so this is consistent with the definitions from the lecture for a finite group $A$, namely $\Lspace[2]\of A = \Functions A \C$, and $\LTwoInner\gy\gj = \sum {g\in A} \conj\gy\of g \gj\of g$. If $X=\Rn$, and $\gm$ is the Lebesgue measure,}
   \LTwoInner\gy\gj &= \int X \conj\gy\gj \diffd \gm = \int \Rn \conj\gy\of \vx \gj\of\vx\diffd\vx\text{,}\\
   \Lnorm[2]\gj&=\int X \abs{\gj}^2 \diffd \gm = \int \Rn \abs{\gj\of \vx}^2 \diffd\vx \text{,}\\
\end{align*}
and again we recover the definition we gave for the inner product on $\Schwartz\StrictSubset\Lspace[2]\of\Rn$.

Now consider the representation $\FunctionSpec \gr G \GeneralLinearGroup\of{\Lspace[2]\of X}, \FunctionBody g {\gr_g}$ of $G$ on $\Lspace[2]\of X$ defined by $\pa{\gr_g\of\gj}\of x =  \gj\of{\LeftAction g x}$.
\paragraph{Fourier Series and $\UnitSphere 1$.}
If $G=\UnitSphere 1=X$ is the circle group, acting on itself by addition (here we use the definition $\UnitSphere 1 = \QuotientGroup\R {2\Pi\Z}$), $\Lspace[2]\of X = \Lspace[2]\of{\UnitSphere 1}$ decomposes under $\gr$ in a way which is dictated by Fourier series. Indeed, we have for $\gj\in \Lspace[2]\of{\UnitSphere 1}$, $j\in\Z$ --- see \emph{The Discrete Fourier Transform}, page~8, though note that the inner product was antilinear in the second argument back then, whereas it is antilinear in the first one this semester:
\begin{equation*}
  \ft\gj\of j = \frac{1}{2\Pi}\int 0[2\Pi] \gj\of \gq \E^{-\I j \gq}\diffd \gq = \int {\UnitSphere 1} \gj \E^{-\I j \placeholder}\diffd \gm = \LTwoInner {\E^{\I j \placeholder}} \gj \quad \text{where $\E^{\I j \placeholder}\DefineAs \FunctionBody \gq {\E^{\I j \gq}}$, $\E^{\I j \placeholder} \in \PontryaginDual{\UnitSphere 1} \Isomorphic \Z$.}
\end{equation*}
by taking $\gm$ normed, i.e., $\gm\of{\UnitSphere 1} = 1$. In other words, $\ft{\placeholder}\of j =  \LTwoInner {\E^{\I j \placeholder}} \placeholder$ is the projection of $\gj$ onto the subspace $V_j\DefineAs\LinearSpan\set{\E^{\I j \placeholder}}$ of $\Lspace[2]\of{\UnitSphere 1}$. Note that the $\E^{\I j \placeholder}$ are exactly the elements of $\PontryaginDual{\UnitSphere 1}$.
Moreover, $V_j$ is $\gr$-invariant, as $\gr$ acts by translation on $\gj\in \Lspace[2]\of{\UnitSphere 1}$, namely $\pa{\gr_\ga\of\gj}\of \gq = \gj\of{\ga+\gq}$, and hence
\begin{equation*} 
\forall \gl\E^{\I j \placeholder} \in V_j \quad
\pa{\gr_\ga\of{\gl\E^{\I j \placeholder}}} =\gl\E^{\I j \pa{\ga+\placeholder}}=\gl\E^{\I j \ga} \E^{\I j \placeholder} \in V_j\text{.}
\end{equation*}
As it is one-dimensional, $V_j$ is irreducible. We also have, with $\LTwoInner {\E^{\I j \placeholder}}{\E^{\I k \placeholder}}= \ft{\E^{\I k \placeholder}}\of j  = \KroneckerDelta j k$, $V_j \Orthogonal V_k$ for $k\neq j$.
By Parseval's identity, $\sum {j\in\Z}\ft\gj\of j \E^{\I j \placeholder}$ converges absolutely to $\gj$ for all $\gj\in\Lspace[2]\of{\UnitSphere 1}$, so
\begin{equation*} \Lspace[2]\of{\UnitSphere 1}=\DirectSum{j\in\Z}
V_j=\DirectSum{\gc\in\PontryaginDual{\UnitSphere 1}} \LinearSpan \gc \text{.}
\end{equation*}
To summarise, the translation action $\gr$ is a unitary representation of $\UnitSphere 1$ on $\Lspace[2]\of{\UnitSphere 1}$ with respect to the inner product $\LTwoInner \placeholder\placeholder$, it decomposes in the irreducible representations $V_j$ which are the spans of individual elements $\E^{\I j \placeholder}$ of $\PontryaginDual{\UnitSphere 1}$ and $\ft{\placeholder}\of{j}$ is the projector onto $V_j$. Since $\PontryaginDual {\UnitSphere 1} \Isomorphic \Z$, and the elements of $\PontryaginDual {\UnitSphere 1}$ are the basis onto which functions are projected by the Fourier transform, it makes sense to think of the projector as $\ft{\placeholder}\of{\E^{\I j \placeholder}}$ instead, with $\ft\gj\of{\gc}\DefineAs\LTwoInner\gc\gj$ for $\gc\in\PontryaginDual {\UnitSphere 1}$.
 
\paragraph{The Fourier transform and $\R$.}
If $G=\Rn=X$ acts by addition on itself, the decomposition of $\Lspace[2]\of X = \Lspace[2]\of{\Rn}$ under $\gr$ is described by the Fourier transform. As above, we have for $\gj\in\Lspace[2]\of\Rn, \vk\in\Rn,$
\begin{equation*}
 \ft\gj\of \vk = \ftnrm\int \Rn \gj\of \vx \E^{-\I \scal\vk \vx}\diffd \vx = \int \Rn \gj \E^{-\I \scal\vk{}}\diffd \gm = \LTwoInner {\E^{\I \scal\vk{}}} \gj
\end{equation*}
by taking $\gm = \ftnrm\LebesgueMeasure n$, where $\LebesgueMeasure n$ is the Lebesgue measure on $\Rn$. Again, we see that the $\E^{\I \scal\vk{}}\DefineAs \FunctionBody \vx \E^{\I \scal\vk{\vx}}$ are exactly the elements of $\PontryaginDual\Rn\Isomorphic\Rn$, and that the $V_\vk\DefineAs\LinearSpan\set{\E^{\I \scal\vk{}}}$ are $\gr$-invariant, where $\gr$ acts by translation and are orthogonal. The projector onto $V_\vk$ is  $\ft{\placeholder}\of \vk$. As for $\gj\in\Lspace[2]\of\Rn$,
\begin{equation*} 
\rft{\ft\gj}\of\vx = \ftnrm\int\Rn\ft\gj\of\vk\E^{\I\scal\vk\vx}\diffd\vk \gj\of\vx=
\int\Rn\ft\gj\E^{\I\scal\vx{}}\diffd \PontryaginDual\gm = \gj\of\vx
\end{equation*}
for almost all $x$ --- $\PontryaginDual\gm$ is the dual measure\footnote{The dual measure $\PontryaginDual\gm$ is the measure we need to get the
  expressions to look the same when written in terms of measures. We chose $\gm$ in such
  a way that $\gm = \PontryaginDual\gm$, but if we had defined a non-unitary version, e.g.
  $\ft\gj\of \vk \DefineAs \int \Rn \gj\of x \E^{-\I \scal\vk \vx}\diffd \vx$, we would  
  need to define the inverse Fourier transform accordingly as
  $\rft\gy\of\vx\DefineAs\sqftnrm \int\Rn\gy\of\vk\E^{\I\scal\vk\vx}\diffd\vx$, i.e., for
  $\gm=\LebesgueMeasure n$, $\PontryaginDual \gm = \sqftnrm \LebesgueMeasure n$.}
---, the representation $\gr$ of $\R$ on $\Lspace[2]\of\R$ by translation decomposes in irreducible representations as
\begin{equation*}
  \Lspace[2]\of{\UnitSphere 1}=\DirectSum{\vk\in\Rn}
  V_\vk=\DirectSum{\gc\in\PontryaginDual{\Rn}} \LinearSpan \gc \text{.}
\end{equation*}
Once again, it makes sense to think of the projectors as  $\ft{\placeholder}\of{\E^{\I \scal\vk{}}}$, with $\ft\gj\of\gc \DefineAs \LTwoInner \gc \gj$ for $\gc\in\PontryaginDual\Rn$, as the isomorphism $\PontryaginDual\Rn\Isomorphic\Rn$ is not unique. Actually, the isomorphism $\FunctionBody \vk {\E^{2 \Pi \I \scal{\vk}{} }}$ is sometimes used, as it allows for $\gm = \PontryaginDual\gm = \LebesgueMeasure n$ --- there are no constant factors before the integrals. Using this isomorphism, the Gaussian $\E^{-\frac{1}{2}\norm\vx^2}$ is no longer self-dual, i.e., the same as its Fourier transform, but $\E^{-\Pi\norm\vx^2}$ is instead.

This also gives us an isomorphism between the momentum space $\CotangentSpace 0 \Rn = \Dual{\pa\Rn}$ and the Pontryagin dual $\PontryaginDual \Rn$, namely $\FunctionBody \vgl {\E^{2 \Pi \I \vgl }}$, with $\PontryaginDual \Rn\owns\FunctionNamedBody{\E^{2 \Pi \I \vgl}} \vk {\E^{2 \Pi \I \vgl\vk}}$, which, in contrast to the isomorphism from $\Rn$ to $\PontryaginDual\Rn$, does not depend on the choice of an inner product. It therefore makes sense to think of momenta as lying in the dual of the tangent space, and not in the tangent space. Thus the phase space should indeed be $\CotangentBundle \Rn$, and not $\TangentBundle \Rn$.

\paragraph{Spherical harmonics and $\SpecialOrthogonalGroup\of 3$.} 
\newcommand{\degL}{\ell}
\newcommand{\Harmonic}[1]{\mathbf{H}_{#1}}
If $G=\SpecialOrthogonalGroup\of 3$ acts by rotations on $X=\UnitSphere 2$, the representation $\gr$ decomposes as 
\begin{equation*}
\Lspace[2]\of{\UnitSphere 2} = \DirectSum{\degL=1}[\infty] \Harmonic\degL\text{,}
\end{equation*}
where the irreducible $\Harmonic\degL$ are defined as follows: $\Harmonic\degL$ is the set of all homogeneous harmonic polynomials of degree $\degL$ on $\UnitSphere 2$, i.e.,
\begin{equation*}
\Harmonic\degL = \setst{\FunctionSpec f {\UnitSphere 2} \C, \FunctionBody {\Transpose{\tuple{x,y,z}}} {f\of{x,y,z}}}{f\of{x,y,z} = \sum {\ga+\gb+\gg = \degL} c_{\ga\,\gb\,\gg} x^{\ga}y^{\gb}z^{\gg} \And \Laplacian f = 0  }\text{.}
\end{equation*}

\endgroup
\end{supplemental}


\begin{lecture}[date=2013-03-21, official=true]
\begingroup
\newcommand{\vsqrtninv}{\frac{1}{\sqrt{\vn}}}
The dual of a group is a sort of nonlinear version of the dual of a vector space.

We switched from an additive to a multiplicative notation. ``Algebraists... you have to be careful. They're sensitive.''

``Representation theory is like a bubble on Wall Street.'' We have, obviously, $\matT  \vsqrtninv = \vsqrtninv$. ``Does nobody know about Elmo?''  Now, by taking this eigenvector and applying $\matM$ over and over again, --- in a perfectly legal manner --- we get all the other eigenvectors! All the representation theory, all the modules, all the things they talk about... it's just this. ``[Claude's] entire thesis is just a super-duper version of this.'' You don't have to do anything, you just talk. This is the French influence.

``We're going to come to the point where you see the difference between [Claude] and me.'' We will need not one, but \emph{two} proofs for the Stone-Von Neumann theorem.

``Why am I not happy [about Proof I] whereas he is happy? [...] I'm only going to talk about mathematical reasons.'' Man cannot live on algebra alone. What happens as $n$ goes to infinity? The proof doesn't converge. He doesn't care. 

The problem is phase transitions: the symmetries change, and you cannot see that with algebra. For instance, for superconductivity, you have to have enough stuff. You cannot just have an explicit $n$. 
``Suddenly, we're going to go back to the Fourier transform.'' 

\noindent
``That's what's good about these algebraists. They're tenacious.''

``We have a new Pope now. You cannot confuse the Father, the Son and the Holy Ghost. If you do, you are going to get in trouble. If you confuse eigenvectors and eigenvalues, you're also going to get into trouble. Not the same kind of trouble though.''

``If you don't come back next week I understand.''
\endgroup
\end{lecture}

\section{All the eigenfunction of the Fourier transform}
\begin{lecture}[date=2013-03-26]
Recall: 
\begin{align*}
\FT\of\gj\of\vk\DefineAs\ft\gj\of\vk&\DefineAs\ftnrm\int\Rn\gj\of\vx\E^{-\I\scal{\vk}{\vx}}\diffd\vx\text{,} &&\gj\in\Schwartz\text,\\
\RFT\of\gy\of\vx\DefineAs\rft\gy\of\vx&\DefineAs\ftnrm\int\Rn\gy\of\vx\E^{\I\scal{\vk}{\vx}}\diffd\vk\text{,} &&\gy\in\Schwartz\text,\\
\FT\RFT &=\RFT\FT=\Identity\text,\\
\FT{\pa{\derivop[2]x + x^2}}\of{k}&=\pa{\derivop[2]x + x^2}\FT\of\gj\of{k}\text.
\end{align*}
So we have this very nice guy here: $\derivop[2]x + x^2$, and having gone to \textgerman{Elementarschule}, you'd think \[\derivop[2]x + x^2 \stackrel{?}= \pa{x-\derivop x}\pa{x+\derivop x}\text{.}\] But the \emph{real} identity they should teach you at school --- life is short, the sooner you get going, the better --- is \[\pa{a-b}\pa{a+b}=a^2-b^2+\commutator a b\text{.}\] That's the difference between childhood and adulthood: $ab$ is no longer equal to $ba$, and it causes a lot of problems.

Here $\commutator {\derivop x} x = \Identity$. We now know  $ \pa{x-\derivop x}\pa{x+\derivop x} = -\derivop[2]x + x^2 -1$.
This will be around long after strings are seen as a strange cult of the 21st century.

We defined:
\begin{align*}
\opA&\DefineAs\frac{1}{\sqrt{2}}\pa{x+\derivop x}\text,\\
\opAdag&\DefineAs\frac{1}{\sqrt{2}}\pa{x+\derivop x}\text.
\end{align*}
We wrote ``dagger''. This makes sense, as;
\begin{align*}
\LTwoInner \gy{\opA\gj} &= \frac{1}{\sqrt{2}}\int\R\conj{\gy}\of x \pa{\derivop x+x}\gj\of x \diffd x\\
&= \frac{1}{\sqrt{2}}\int\R\conj{\gy}\of x \derivop x\gj\of x \diffd x +
\frac{1}{\sqrt{2}}\int\R\conj{\pa{x\gy\of x}} \gj\of x \diffd x\\
&=\int\R\conj{\pa{\frac{1}{\sqrt{2}}\pa{-\derivop x + x}\gy\of x}} \gj\of x \diffd x \\
&=\LTwoInner {\opAdag \gy}\gj\text.
\end{align*}

Write 
\begin{align*}
\opA_x&\DefineAs\frac{1}{\sqrt{2}}\pa{x+\derivop x}\text,\\
\adj{\opA_x}&\DefineAs\frac{1}{\sqrt{2}}\pa{x+\derivop x}\text{,}
\end{align*}
and similarly for $k$ instead of $x$.
Observe:
\begin{align*}
\FT\of {\opA_x \gj}\of k &= \I \opA_k \ft\gj\of k\text,\\
\FT\of {\adj{\opA_x} \gj}\of k &= \I \adj{\opA_k} \ft\gj\of k\text,\\
\opA_x\E^{-\frac{1}{2}x^2}&=\pa{\derivop x+x}\E^{-\frac{1}{2}x^2}= 0\text{.}\\
\intertext{define}
h_0\of x &\DefineAs \frac{\E^{-\frac{1}{2}x^2}}{\sqrt[4]{\Pi}}\\
\end{align*}
so that $\LTwoInner {h_0}{h_0} = 1$.

We now can perform the following induction:
\begin{align*}
\opA h_0&=0\text, \\
\ft{h_0}&= h_0\text,\\
\ft{\adj {\opA_x} h_0}\of k &=\pa{-\I}\adj{\opA_k} h_0\of k\text{ using the vital lemma,}\\
\FT\of{\pa{\adj{\opA_x}}^n h_0}\of k &= \pa{-\I} \adj{\opA_k}\FT\of{\pa{\adj \opA_x}^{n-1}h_0}\of k
= \pa{-\I}^n \pa{\adj{\opA_k}}^n h_0\of k\text.
\end{align*}
In other words, the $\pa{\opAdag}^n h_0$ --- with an $\opAdag$, not an $\opA$; ``a dagger can be the difference between life and death!'' --- are eigenfunctions of the the Fourier transform. We will need to prove that these form a complete set, and we will have an orthogonal basis of $\SchwartzSpace\of\R$.
``I'll do some coherent states. I like coherent states.'' Next week we shall prove:
\begin{align*}
\commutator A {\adj A} &= \Identity \text,\\
\commutator A {\pa{\adj A}^n} &= n \pa{\adj A}^{n-1} \text.
\end{align*}
This is the only real idea in group representations: you find some commutation relations, and you generate all the eigenvectors and eigenvalues.

\end{lecture}

\end{document}
